<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Memoria Técnica: Implementación de LLM Causal desde Cero</title>
    <style>
        :root {
            --primary: #1a365d;
            --secondary: #2c5282;
            --accent: #3182ce;
            --text: #2d3748;
            --bg: #ffffff;
            --sidebar: #f7fafc;
        }
        body {
            font-family: 'Charter', 'Georgia', serif;
            line-height: 1.8;
            color: var(--text);
            margin: 0;
            display: flex;
            background-color: #edf2f7;
        }
        .sidebar {
            width: 280px;
            background: var(--primary);
            color: white;
            height: 100vh;
            position: fixed;
            padding: 40px 20px;
            box-sizing: border-box;
            display: none; /* Oculto en móviles */
        }
        @media (min-width: 1024px) { .sidebar { display: block; } .main-content { margin-left: 280px; } }
        .main-content {
            flex: 1;
            background: var(--bg);
            padding: 80px 10%;
            min-height: 100vh;
            box-sizing: border-box;
        }
        header {
            border-bottom: 2px solid var(--primary);
            margin-bottom: 60px;
            padding-bottom: 20px;
        }
        h1 {
            font-size: 3rem;
            color: var(--primary);
            margin: 0;
            line-height: 1.2;
        }
        h2 {
            font-size: 1.8rem;
            color: var(--secondary);
            margin-top: 50px;
            border-bottom: 1px solid #e2e8f0;
            padding-bottom: 10px;
        }
        h3 {
            font-size: 1.4rem;
            color: var(--accent);
            margin-top: 30px;
        }
        .abstract {
            font-style: italic;
            background: var(--sidebar);
            padding: 30px;
            border-radius: 8px;
            margin: 30px 0;
            border-left: 5px solid var(--primary);
        }
        .tech-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin: 30px 0;
        }
        .tech-card {
            background: #fff;
            border: 1px solid #e2e8f0;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.05);
        }
        .code-block {
            background: #1a202c;
            color: #cbd5e0;
            padding: 25px;
            border-radius: 6px;
            font-family: 'Fira Code', monospace;
            font-size: 0.9rem;
            margin: 25px 0;
            overflow-x: auto;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 40px 0;
        }
        th {
            background: var(--primary);
            color: white;
            padding: 15px;
            text-align: left;
        }
        td {
            padding: 15px;
            border-bottom: 1px solid #e2e8f0;
        }
        .footer {
            margin-top: 100px;
            text-align: center;
            font-size: 0.9rem;
            color: #718096;
            border-top: 1px solid #e2e8f0;
            padding-top: 40px;
        }
    </style>
</head>
<body>

<div class="sidebar">
    <h3>Contenidos</h3>
    <ul style="list-style: none; padding: 0; font-size: 0.9rem; line-height: 2;">
        <li>01. Introducción</li>
        <li>02. Arquitectura del Sistema</li>
        <li>03. Pipeline de Datos</li>
        <li>04. Entrenamiento y Hiperparámetros</li>
        <li>05. Inferencia y Optimización</li>
        <li>06. Conclusiones</li>
    </ul>
</div>

<div class="main-content">
    <header>
        <p style="text-transform: uppercase; letter-spacing: 2px; color: var(--accent); font-weight: bold; margin-bottom: 10px;">Memoria de Proyecto Final</p>
        <h1>Implementación y Entrenamiento de un Modelo de Lenguaje Causal (LLM)</h1>
        <p>Desarrollo integral de una solución de IA para asistencia culinaria mediante arquitecturas GPT optimizadas.</p>
    </header>

    <section class="abstract">
        <strong>Resumen Técnico:</strong> Este proyecto documenta el proceso completo de ingeniería para crear un modelo de lenguaje autoregresivo. Se aborda desde la generación de un dataset sintético en formato JSONL, pasando por la definición de una arquitectura Transformer personalizada, hasta la optimización del modelo final en formato GGUF para entornos de baja latencia.
    </section>

    <h2>1. Introducción y Objetivos</h2>
    <p>
        El objetivo principal de este proyecto es demostrar la viabilidad de entrenar modelos de lenguaje específicos de dominio sin depender de infraestructuras de cómputo masivas. A diferencia de las soluciones de "caja negra", este desarrollo permite un control total sobre el vocabulario y la lógica de respuesta del asistente.
    </p>

    <h2>2. Arquitectura del Modelo: El Cerebro Digital</h2>
    <p>
        Se ha implementado una variante de la arquitectura <strong>Transformer Decoder-Only</strong>. Esta arquitectura se basa en el mecanismo de atención para calcular la relevancia de cada palabra en relación con las demás dentro de una secuencia culinaria.
    </p>
    
    <div class="tech-grid">
        <div class="tech-card">
            <strong>Self-Attention</strong><br>
            Permite al modelo entender que en la frase "Bate el huevo hasta que esté espumoso", la palabra "espumoso" se refiere al "huevo".
        </div>
        <div class="tech-card">
            <strong>Causal Masking</strong><br>
            Asegura que el modelo solo aprenda a predecir la palabra siguiente basándose en las anteriores, nunca en las futuras.
        </div>
        <div class="tech-card">
            <strong>Feed-Forward Networks</strong><br>
            Capas densas que procesan las representaciones obtenidas por la atención para extraer patrones complejos.
        </div>
    </div>

    <h2>3. Ciclo de Vida del Dato (Data Engineering)</h2>
    <p>
        La base del conocimiento reside en <code>generate_dataset.py</code>. El proceso de ingeniería de datos se divide en:
    </p>
    <ul>
        <li><strong>Estructuración:</strong> Conversión de diccionarios de recetas en pares <code>instruction-output</code>.</li>
        <li><strong>Serialización JSONL:</strong> Uso de líneas JSON para permitir el streaming de datos durante el entrenamiento, optimizando el uso de memoria volátil.</li>
    </ul>

    <h2>4. Proceso de Entrenamiento</h2>
    <p>
        El entrenamiento se realizó bajo un esquema de <strong>entrenamiento desde cero</strong>. Esto significa que el modelo comenzó con una distribución de pesos aleatoria (Ruido Gaussiano).
    </p>

    <table>
        <thead>
            <tr>
                <th>Configuración</th>
                <th>Valor</th>
                <th>Propósito</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td>Capas (Layers)</td>
                <td>6</td>
                <td>Balance entre profundidad semántica y velocidad.</td>
            </tr>
            <tr>
                <td>Épocas</td>
                <td>100</td>
                <td>Garantizar la convergencia en un dataset de nicho.</td>
            </tr>
            <tr>
                <td>Learning Rate</td>
                <td>5e-4</td>
                <td>Ajuste dinámico de pesos para evitar mínimos locales.</td>
            </tr>
            <tr>
                <td>Precision</td>
                <td>FP16</td>
                <td>Uso de tensores de media precisión para aceleración en GPU.</td>
            </tr>
        </tbody>
    </table>

    <h2>5. Inferencia y Despliegue (GGUF)</h2>
    <p>
        El hito final del proyecto es la conversión al formato <strong>GGUF</strong>. Este paso es vital para la democratización de la IA, ya que permite:
    </p>
    <ol>
        <li><strong>Cuantización:</strong> Reducción del tamaño del modelo de 32 bits a 4 u 8 bits con mínima pérdida de precisión.</li>
        <li><strong>Inferencia en CPU:</strong> Eliminación de la dependencia de tarjetas gráficas costosas.</li>
        <li><strong>Portabilidad:</strong> Un único archivo binario que contiene pesos, metadatos y tokenizador.</li>
    </ol>

    <h2>6. Conclusiones y Resultados</h2>
    <p>
        El asistente culinario resultante demuestra una alta capacidad para seguir instrucciones y mantener la coherencia en recetas complejas. La metodología aplicada valida que el entrenamiento "from scratch" es una alternativa poderosa para aplicaciones donde la privacidad de los datos y la especificidad del dominio son prioritarias.
    </p>

    <div class="footer">
        <p><strong>Memoria de Proyecto: IA Culinaria</strong></p>
        <p>Desarrollado en el marco de la asignatura de Procesamiento de Lenguaje Natural / Machine Learning.</p>
        <p>2026</p>
    </div>
</div>

</body>
</html>