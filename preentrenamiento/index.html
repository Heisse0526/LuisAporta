<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Manual Pre-Entrenamiento</title>
    <style>
        :root {
            --bg-color: #0d1117;
            --card-bg: #161b22;
            --text-color: #c9d1d9;
            --accent-color: #58a6ff;
            --code-bg: #21262d;
            --border-color: #30363d;
        }
        body {
            font-family: 'Segoe UI', 'Roboto', Helvetica, Arial, sans-serif;
            background-color: var(--bg-color);
            color: var(--text-color);
            margin: 0;
            padding: 0;
            line-height: 1.6;
        }
        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 40px 20px;
        }
        h1 {
            color: var(--accent-color);
            text-align: center;
            font-size: 2.5rem;
            margin-bottom: 40px;
            border-bottom: 1px solid var(--border-color);
            padding-bottom: 20px;
        }
        .section-card {
            background-color: var(--card-bg);
            border: 1px solid var(--border-color);
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 30px;
            box-shadow: 0 4px 12px rgba(0,0,0,0.1);
        }
        h2 {
            color: var(--accent-color);
            margin-top: 0;
            border-bottom: 1px solid var(--border-color);
            padding-bottom: 10px;
            margin-bottom: 20px;
        }
        p { margin-bottom: 16px; }
        
        .code-block {
            background-color: var(--code-bg);
            padding: 12px;
            border-radius: 6px;
            font-family: 'Consolas', 'Monaco', 'Courier New', monospace;
            font-size: 0.9rem;
            overflow-x: auto;
            border: 1px solid var(--border-color);
            color: #ff7b72;
            margin: 10px 0;
        }
        
        .image-gallery {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
            margin-top: 24px;
        }
        .img-wrapper {
            position: relative;
            overflow: hidden;
            border-radius: 6px;
            border: 1px solid var(--border-color);
            cursor: pointer;
        }
        img {
            width: 100%;
            height: auto;
            display: block;
            transition: transform 0.3s ease;
        }
        .img-wrapper:hover img {
            transform: scale(1.03);
        }
        
        /* Lightbox */
        #lightbox {
            display: none;
            position: fixed;
            z-index: 1000;
            top: 0; left: 0;
            width: 100%; height: 100%;
            background-color: rgba(0,0,0,0.9);
            justify-content: center;
            align-items: center;
        }
        #lightbox img {
            max-width: 90%;
            max-height: 90%;
            border: 2px solid var(--accent-color);
            border-radius: 4px;
        }
        #lightbox.active { display: flex; }
    </style>
</head>
<body>
    <div class="container">
        <h1>Documentación: Entrenamiento y Despliegue</h1>
        <div class="section-card">
            <h2>Introducción</h2>
            <p>Documentación de Proyecto: Entrenamiento y Despliegue de LLM Local (Cervantes-GPT)</p>
            <p>Fecha: 5 de Febrero, 2026 Hardware: NVIDIA GeForce RTX 4070 (12GB VRAM) Sistema Operativo: Windows 11 + WSL2 (Ubuntu 24.04) Objetivo: Entrenar un Modelo de Lenguaje (LLM) desde cero con el texto de "El Quijote", convertirlo a formato estándar GGUF y ejecutarlo en una interfaz de usuario final (LM Studio).</p>
        </div>
        <div class="section-card">
            <h2>1. Configuración del Entorno de Alto Rendimiento</h2>
            <p>Para aprovechar la aceleración por hardware de la RTX 4070, se descartó el uso de Windows nativo en favor del Subsistema de Linux para Windows (WSL2), debido a su mejor gestión de memoria y compatibilidad con herramientas de IA.</p>
            <p>1.1 Instalación de WSL2 y Dependencias</p>
            <p>Comando: wsl --install (PowerShell Admin).</p>
            <p>Distribución: Ubuntu.</p>
            <p>Preparación: Actualización de paquetes (apt update && upgrade).</p>
            <p>1.2 Gestión de Entornos Python</p>
            <p>Al intentar instalar librerías, encontramos el error externally-managed-environment (propio de versiones modernas de Ubuntu).</p>
            <p>Solución: Uso de entornos virtuales (venv) para aislar el proyecto.</p>
            <p>Bash</p>
            <div class="code-block">python3 -m venv venv</div>
            <div class="code-block">source venv/bin/activate</div>
            <p>1.3 Instalación de PyTorch con CUDA</p>
            <p>Se instaló la versión específica compatible con los drivers de NVIDIA para habilitar la GPU:</p>
            <p>Bash</p>
            <div class="code-block">pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121</div>
            <p>Verificación: torch.cuda.is_available() devolvió True detectando la RTX 4070.</p>
            <div class="image-gallery">
                <div class="img-wrapper" onclick="openLightbox(this)">
                    <img src="Paso_1_Configuracion_Entorno_Inicial.png" alt="Paso_1_Configuracion_Entorno_Inicial.png" loading="lazy">
                </div>
                <div class="img-wrapper" onclick="openLightbox(this)">
                    <img src="Paso_1_Creacion_Venv.png" alt="Paso_1_Creacion_Venv.png" loading="lazy">
                </div>
                <div class="img-wrapper" onclick="openLightbox(this)">
                    <img src="Paso_1_Instalacion_PyTorch_CUDA.png" alt="Paso_1_Instalacion_PyTorch_CUDA.png" loading="lazy">
                </div>
            </div>
        </div>
        <div class="section-card">
            <h2>2. Fase 1: Entrenamiento Educativo (NanoGPT)</h2>
            <p>Se realizó un primer entrenamiento utilizando una arquitectura Transformer "artesanal" (basada en NanoGPT) para comprender los conceptos de Loss, Tokens y Atención.</p>
            <p>Script: entrenar.py.</p>
            <p>Configuración: Batch size aumentado a 64 y contexto de 256 tokens para aprovechar la VRAM de la 4070.</p>
            <p>Resultado: El modelo aprendió a estructurar palabras y frases estilo castellano antiguo.</p>
            <p>Limitación: Al ser una arquitectura personalizada, no era compatible con herramientas de conversión estándar (llama.cpp). No se podía exportar a GGUF.</p>
            <div class="image-gallery">
                <div class="img-wrapper" onclick="openLightbox(this)">
                    <img src="Paso_2_Generacion_Texto_NanoGPT.png" alt="Paso_2_Generacion_Texto_NanoGPT.png" loading="lazy">
                </div>
                <div class="img-wrapper" onclick="openLightbox(this)">
                    <img src="Paso_2_Inicio_Entrenamiento_NanoGPT.png" alt="Paso_2_Inicio_Entrenamiento_NanoGPT.png" loading="lazy">
                </div>
                <div class="img-wrapper" onclick="openLightbox(this)">
                    <img src="Paso_2_Monitoreo_GPU_NanoGPT.png" alt="Paso_2_Monitoreo_GPU_NanoGPT.png" loading="lazy">
                </div>
            </div>
        </div>
        <div class="section-card">
            <h2>3. Fase 2: Entrenamiento para Producción (GPT-2 + HuggingFace)</h2>
            <p>Para lograr la exportación a LM Studio, se migró a una arquitectura estándar (GPT-2) utilizando la librería transformers.</p>
            <p>3.1 Retos Técnicos y Soluciones</p>
            <p>Durante la creación del script entrenar_gpt2.py, surgieron varios errores críticos debido a actualizaciones recientes de las librerías:</p>
            <p>Error ImportError: cannot import name 'TextDataset':</p>
            <p>Causa: La función fue eliminada en versiones recientes de transformers.</p>
            <p>Solución: Se programó una clase personalizada MiDatasetDeTexto(Dataset) que tokeniza el texto y lo divide en bloques manualmente.</p>
            <p>Error TrainingArguments... overwrite_output_dir:</p>
            <p>Causa: Cambio en la API de HuggingFace.</p>
            <p>Solución: Se implementó limpieza manual de carpetas usando la librería shutil de Python antes de iniciar el entrenamiento.</p>
            <p>Warning de Longitud de Tokens:</p>
            <p>Solución: Se ajustó el tokenizer.model_max_length para evitar advertencias al procesar el texto completo del Quijote.</p>
            <p>3.2 Ejecución Exitosa</p>
            <p>El modelo se entrenó durante 3 épocas. La RTX 4070 completó el proceso en minutos. El modelo resultante se guardó en formato HuggingFace (pytorch_model.bin).</p>
            <div class="image-gallery">
                <div class="img-wrapper" onclick="openLightbox(this)">
                    <img src="Paso_3_Instalacion_Librerias_HF.png" alt="Paso_3_Instalacion_Librerias_HF.png" loading="lazy">
                </div>
            </div>
        </div>
        <div class="section-card">
            <h2>4. Fase 3: Compilación y Conversión (Llama.cpp)</h2>
            <p>Para convertir el modelo a GGUF (formato optimizado para inferencia local), se utilizó la herramienta llama.cpp.</p>
            <p>4.1 Compilación de Herramientas C++</p>
            <p>Se instalaron build-essential, git y cmake.</p>
            <p>Incidencia: El comando make falló porque el proyecto migró a cmake.</p>
            <p>Solución: Se utilizó el nuevo sistema de construcción:</p>
            <p>Bash</p>
            <div class="code-block">cmake -B build</div>
            <div class="code-block">cmake --build build --config Release -j 8</div>
            <p>4.2 Resolución de Conflictos de Python</p>
            <p>El archivo requirements.txt de llama.cpp generaba conflictos con torchaudio.</p>
            <p>Solución: Instalación quirúrgica de solo lo necesario: pip install gguf protobuf.</p>
            <p>4.3 Generación del GGUF</p>
            <p>Se ejecutó el script de conversión sobre el modelo entrenado en la Fase 2:</p>
            <p>Bash</p>
            <div class="code-block">python3 convert_hf_to_gguf.py ../modelo_quijote_hf --outfile ../quijote.gguf</div>
            <p>Resultado: Archivo quijote.gguf generado correctamente.</p>
            <div class="image-gallery">
                <div class="img-wrapper" onclick="openLightbox(this)">
                    <img src="Paso_4_Instalacion_Herramientas_Compilacion.png" alt="Paso_4_Instalacion_Herramientas_Compilacion.png" loading="lazy">
                </div>
                <div class="img-wrapper" onclick="openLightbox(this)">
                    <img src="Paso_4_Verificacion_Modelo_GGUF_Terminal.png" alt="Paso_4_Verificacion_Modelo_GGUF_Terminal.png" loading="lazy">
                </div>
            </div>
        </div>
        <div class="section-card">
            <h2>5. Fase 4: Despliegue en LM Studio (Windows)</h2>
            <p>El paso final consistió en mover el archivo de Linux a Windows y ejecutarlo.</p>
            <p>5.1 Estructura de Directorios</p>
            <p>LM Studio no reconocía el modelo inicialmente.</p>
            <p>Solución: Se tuvo que cumplir la estructura estricta de carpetas: C:\Users\Usuario\.cache\lm-studio\models\Paco\Quijote\quijote.gguf</p>
            <p>5.2 Bloqueo de Seguridad de Windows</p>
            <p>Al intentar cargar el modelo, apareció el error: "Una directiva de Control de aplicaciones bloqueó este archivo".</p>
            <p>Diagnóstico: Smart App Control o Windows Defender bloquearon las librerías no firmadas del motor de inferencia.</p>
            <p>Soluciones aplicadas:</p>
            <p>Ejecutar LM Studio como Administrador.</p>
            <p>Añadir la carpeta .lmstudio a exclusiones de Windows Defender.</p>
            <p>(Opcional) Desactivar Smart App Control.</p>
        </div>
        <div class="section-card">
            <h2>6. Resultado Final</h2>
            <p>El modelo Cervantes-GPT es funcional.</p>
            <p>Capacidad: Autocompletado de texto (Text Completion).</p>
            <p>Rendimiento: Generación instantánea gracias a la ejecución local.</p>
            <p>Estilo: Imita el vocabulario y gramática del Siglo de Oro español.</p>
            <p>Conclusión del proyecto: Se ha logrado dominar el ciclo completo de MLOps (Machine Learning Operations) a pequeña escala: Datos -> Entrenamiento (GPU) -> Validación -> Conversión/Compilación -> Despliegue en Producción.</p>
        </div>
    </div>
    
    <div id="lightbox" onclick="this.classList.remove('active')">
        <img id="lightbox-img" src="" alt="Full size">
    </div>

    <script>
        function openLightbox(element) {
            const imgSrc = element.querySelector('img').src;
            document.getElementById('lightbox-img').src = imgSrc;
            document.getElementById('lightbox').classList.add('active');
        }
    </script>
</body>
</html>